{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa31a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58610f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio   \n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3  \\\n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Srushti-S/BE_Assignments/main/LP5/DL/boston_housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3f455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['MEDV']\n",
    "X = df.drop(['MEDV'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb07824",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43e53a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3cc36",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ceb625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=X_train[0].shape, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='relu'),\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8be91d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 1s 21ms/step - loss: 556.9379 - mae: 21.7468 - val_loss: 514.6926 - val_mae: 21.2733\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 514.8693 - mae: 20.7279 - val_loss: 459.9009 - val_mae: 19.8931\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 443.9296 - mae: 18.8297 - val_loss: 364.6703 - val_mae: 17.2836\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 332.8477 - mae: 15.5225 - val_loss: 235.3600 - val_mae: 13.3974\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 207.7060 - mae: 11.2852 - val_loss: 126.7072 - val_mae: 9.3137\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 134.7483 - mae: 8.9306 - val_loss: 99.0676 - val_mae: 7.9270\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 117.6753 - mae: 8.3657 - val_loss: 86.0222 - val_mae: 7.2525\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 102.1722 - mae: 7.6442 - val_loss: 71.1726 - val_mae: 6.5996\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 89.4405 - mae: 6.9082 - val_loss: 61.1366 - val_mae: 6.1001\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 79.0969 - mae: 6.4259 - val_loss: 52.6164 - val_mae: 5.6600\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 70.9231 - mae: 6.0476 - val_loss: 46.1622 - val_mae: 5.2871\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 65.2250 - mae: 5.8275 - val_loss: 41.4889 - val_mae: 4.9411\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 59.9584 - mae: 5.4772 - val_loss: 38.3104 - val_mae: 4.7280\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 56.9427 - mae: 5.2584 - val_loss: 35.4734 - val_mae: 4.4719\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 54.2705 - mae: 5.1089 - val_loss: 33.7707 - val_mae: 4.3273\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 52.1541 - mae: 5.0840 - val_loss: 32.1960 - val_mae: 4.2455\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 50.4827 - mae: 5.0014 - val_loss: 30.7835 - val_mae: 4.1392\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 48.7255 - mae: 4.8774 - val_loss: 29.3905 - val_mae: 4.0360\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 47.0849 - mae: 4.7806 - val_loss: 28.2091 - val_mae: 3.9677\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 45.5205 - mae: 4.6941 - val_loss: 26.8480 - val_mae: 3.8627\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 44.3943 - mae: 4.5718 - val_loss: 25.7099 - val_mae: 3.7891\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 42.1210 - mae: 4.5271 - val_loss: 24.7400 - val_mae: 3.8198\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 40.8314 - mae: 4.5072 - val_loss: 23.4498 - val_mae: 3.7150\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 39.0731 - mae: 4.3369 - val_loss: 22.3540 - val_mae: 3.6663\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 37.8025 - mae: 4.2894 - val_loss: 21.3607 - val_mae: 3.6497\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 36.1394 - mae: 4.1700 - val_loss: 20.2736 - val_mae: 3.5563\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 35.0294 - mae: 4.0365 - val_loss: 19.5132 - val_mae: 3.5497\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.6811 - mae: 4.0976 - val_loss: 18.8605 - val_mae: 3.5359\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.0908 - mae: 3.8937 - val_loss: 17.5487 - val_mae: 3.3728\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 31.0373 - mae: 3.8060 - val_loss: 17.0464 - val_mae: 3.3857\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 29.9866 - mae: 3.7686 - val_loss: 16.2954 - val_mae: 3.2840\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 29.1798 - mae: 3.7502 - val_loss: 15.9040 - val_mae: 3.2984\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 27.8005 - mae: 3.5707 - val_loss: 14.8368 - val_mae: 3.1742\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 26.6963 - mae: 3.4981 - val_loss: 14.5211 - val_mae: 3.1431\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 26.0822 - mae: 3.5207 - val_loss: 13.6376 - val_mae: 3.0378\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.4082 - mae: 3.3623 - val_loss: 13.7276 - val_mae: 3.0662\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 24.6956 - mae: 3.4195 - val_loss: 13.9076 - val_mae: 3.0819\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 23.7202 - mae: 3.2912 - val_loss: 12.3568 - val_mae: 2.9163\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 23.1831 - mae: 3.2140 - val_loss: 12.9605 - val_mae: 2.9870\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 23.3049 - mae: 3.3709 - val_loss: 12.1781 - val_mae: 2.8786\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 22.6547 - mae: 3.1734 - val_loss: 12.1976 - val_mae: 2.9076\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 21.6825 - mae: 3.1912 - val_loss: 12.5590 - val_mae: 2.9340\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 21.4929 - mae: 3.1395 - val_loss: 11.5491 - val_mae: 2.7945\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 20.8216 - mae: 3.1030 - val_loss: 12.2823 - val_mae: 2.8927\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 20.6093 - mae: 3.0834 - val_loss: 11.7137 - val_mae: 2.8252\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 20.4272 - mae: 3.0659 - val_loss: 11.4375 - val_mae: 2.7673\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 20.0447 - mae: 3.0068 - val_loss: 11.8006 - val_mae: 2.8179\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 19.7229 - mae: 3.0097 - val_loss: 11.7065 - val_mae: 2.8076\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 19.8863 - mae: 2.9594 - val_loss: 12.1598 - val_mae: 2.8382\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 19.4615 - mae: 3.0508 - val_loss: 11.3930 - val_mae: 2.7209\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 19.7959 - mae: 2.9351 - val_loss: 11.5990 - val_mae: 2.7337\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 19.3555 - mae: 3.0324 - val_loss: 11.0384 - val_mae: 2.6503\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.9544 - mae: 2.9048 - val_loss: 11.4964 - val_mae: 2.7350\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.3152 - mae: 2.9195 - val_loss: 10.8428 - val_mae: 2.6366\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 18.2291 - mae: 2.9067 - val_loss: 10.4548 - val_mae: 2.5498\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.8507 - mae: 2.8128 - val_loss: 10.8252 - val_mae: 2.6473\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 17.7112 - mae: 2.8147 - val_loss: 11.2595 - val_mae: 2.7266\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.6222 - mae: 2.8530 - val_loss: 10.8265 - val_mae: 2.6224\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.3057 - mae: 2.8020 - val_loss: 10.5083 - val_mae: 2.5719\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 17.1163 - mae: 2.7723 - val_loss: 10.5001 - val_mae: 2.5795\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 17.0182 - mae: 2.7870 - val_loss: 10.6972 - val_mae: 2.6105\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 16.8066 - mae: 2.7486 - val_loss: 10.5313 - val_mae: 2.6069\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 16.7843 - mae: 2.7976 - val_loss: 10.3059 - val_mae: 2.5568\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 16.6103 - mae: 2.7028 - val_loss: 10.4660 - val_mae: 2.5934\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 16.7799 - mae: 2.8500 - val_loss: 9.8148 - val_mae: 2.4548\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 16.5377 - mae: 2.7173 - val_loss: 10.3902 - val_mae: 2.5930\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16.0901 - mae: 2.7253 - val_loss: 9.5374 - val_mae: 2.4117\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16.0097 - mae: 2.6911 - val_loss: 10.8560 - val_mae: 2.7205\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.7889 - mae: 2.7015 - val_loss: 9.3360 - val_mae: 2.3948\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.6370 - mae: 2.6636 - val_loss: 10.5821 - val_mae: 2.6723\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.4846 - mae: 2.7171 - val_loss: 9.5910 - val_mae: 2.4508\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.5218 - mae: 2.6457 - val_loss: 9.5798 - val_mae: 2.4786\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 15.0521 - mae: 2.6429 - val_loss: 9.9998 - val_mae: 2.6031\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.9902 - mae: 2.6258 - val_loss: 9.4006 - val_mae: 2.4844\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 14.9450 - mae: 2.6175 - val_loss: 9.1754 - val_mae: 2.4332\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.6827 - mae: 2.5937 - val_loss: 9.0719 - val_mae: 2.4125\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.6541 - mae: 2.5792 - val_loss: 9.3580 - val_mae: 2.5072\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.4169 - mae: 2.5868 - val_loss: 8.6544 - val_mae: 2.3647\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.3258 - mae: 2.5575 - val_loss: 9.1829 - val_mae: 2.4798\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.4664 - mae: 2.6485 - val_loss: 7.9840 - val_mae: 2.2537\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.1906 - mae: 2.5620 - val_loss: 9.7341 - val_mae: 2.6338\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.1359 - mae: 2.5915 - val_loss: 7.6601 - val_mae: 2.2120\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 13.9484 - mae: 2.5191 - val_loss: 9.4080 - val_mae: 2.5679\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 13.9351 - mae: 2.6155 - val_loss: 7.5559 - val_mae: 2.2127\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.3818 - mae: 2.5599 - val_loss: 10.2363 - val_mae: 2.7413\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13.8065 - mae: 2.5166 - val_loss: 7.7968 - val_mae: 2.2384\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13.3541 - mae: 2.5128 - val_loss: 8.3553 - val_mae: 2.3854\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 13.4194 - mae: 2.4800 - val_loss: 7.7769 - val_mae: 2.2821\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.9341 - mae: 2.4877 - val_loss: 8.7412 - val_mae: 2.4906\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 13.1156 - mae: 2.4797 - val_loss: 7.8935 - val_mae: 2.2998\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.9823 - mae: 2.4775 - val_loss: 8.6645 - val_mae: 2.4548\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.8155 - mae: 2.4444 - val_loss: 8.0450 - val_mae: 2.3548\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.6465 - mae: 2.4535 - val_loss: 8.1003 - val_mae: 2.3798\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.4730 - mae: 2.4159 - val_loss: 7.6292 - val_mae: 2.2919\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.8625 - mae: 2.4442 - val_loss: 9.3793 - val_mae: 2.6630\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.8729 - mae: 2.5033 - val_loss: 6.6579 - val_mae: 2.0711\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.5817 - mae: 2.4242 - val_loss: 7.8029 - val_mae: 2.3384\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.2034 - mae: 2.4096 - val_loss: 7.5583 - val_mae: 2.3043\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 12.0949 - mae: 2.3734 - val_loss: 7.7317 - val_mae: 2.3362\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.2432 - mae: 2.4189 - val_loss: 7.0082 - val_mae: 2.1513\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12.2835 - mae: 2.4029 - val_loss: 9.6466 - val_mae: 2.7063\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.5978 - mae: 2.4718 - val_loss: 6.9541 - val_mae: 2.1854\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.0367 - mae: 2.4393 - val_loss: 7.0026 - val_mae: 2.2018\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.0977 - mae: 2.3760 - val_loss: 7.8587 - val_mae: 2.3921\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.8227 - mae: 2.4129 - val_loss: 6.8554 - val_mae: 2.1596\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.7001 - mae: 2.3567 - val_loss: 8.0316 - val_mae: 2.4013\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 11.4474 - mae: 2.3359 - val_loss: 6.9864 - val_mae: 2.2218\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 11.3201 - mae: 2.3317 - val_loss: 7.3712 - val_mae: 2.3006\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.3280 - mae: 2.3259 - val_loss: 6.9443 - val_mae: 2.2131\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.3416 - mae: 2.3632 - val_loss: 6.8506 - val_mae: 2.2007\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.2532 - mae: 2.2991 - val_loss: 7.1431 - val_mae: 2.2520\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.3259 - mae: 2.3776 - val_loss: 6.8056 - val_mae: 2.1934\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.1877 - mae: 2.3005 - val_loss: 6.6516 - val_mae: 2.1463\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.1855 - mae: 2.3483 - val_loss: 6.8328 - val_mae: 2.2007\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.8596 - mae: 2.2795 - val_loss: 7.0933 - val_mae: 2.2564\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.9763 - mae: 2.3098 - val_loss: 6.3666 - val_mae: 2.0777\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.8289 - mae: 2.2843 - val_loss: 6.8232 - val_mae: 2.2297\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.7423 - mae: 2.2716 - val_loss: 6.8159 - val_mae: 2.2259\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.7247 - mae: 2.2741 - val_loss: 6.9675 - val_mae: 2.2240\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 10.7863 - mae: 2.2970 - val_loss: 6.4311 - val_mae: 2.1339\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.5321 - mae: 2.2628 - val_loss: 6.3584 - val_mae: 2.1257\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.5856 - mae: 2.2905 - val_loss: 6.8001 - val_mae: 2.2199\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 10.4018 - mae: 2.2351 - val_loss: 6.4783 - val_mae: 2.1575\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.6341 - mae: 2.3056 - val_loss: 5.8346 - val_mae: 1.9334\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.4545 - mae: 2.2445 - val_loss: 6.8406 - val_mae: 2.2447\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.4839 - mae: 2.2864 - val_loss: 5.8661 - val_mae: 1.9693\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.2670 - mae: 2.2515 - val_loss: 6.6502 - val_mae: 2.1849\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.2280 - mae: 2.2477 - val_loss: 6.0462 - val_mae: 2.0411\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.2159 - mae: 2.2301 - val_loss: 6.8811 - val_mae: 2.2510\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.0437 - mae: 2.2292 - val_loss: 6.1367 - val_mae: 2.0714\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.0883 - mae: 2.2147 - val_loss: 7.0971 - val_mae: 2.2605\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.2240 - mae: 2.2588 - val_loss: 5.6367 - val_mae: 1.8938\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.0399 - mae: 2.2208 - val_loss: 6.5083 - val_mae: 2.1783\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 10.0551 - mae: 2.2097 - val_loss: 6.4910 - val_mae: 2.1798\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.8969 - mae: 2.2311 - val_loss: 5.6103 - val_mae: 1.9310\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.7971 - mae: 2.1900 - val_loss: 6.4882 - val_mae: 2.1828\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.8133 - mae: 2.2286 - val_loss: 5.8758 - val_mae: 2.0255\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.9354 - mae: 2.2008 - val_loss: 7.5101 - val_mae: 2.3661\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.0274 - mae: 2.2645 - val_loss: 5.3084 - val_mae: 1.8213\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6616 - mae: 2.1619 - val_loss: 6.5685 - val_mae: 2.1946\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.8154 - mae: 2.2448 - val_loss: 5.5670 - val_mae: 1.9266\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.5333 - mae: 2.1927 - val_loss: 6.6875 - val_mae: 2.2115\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.5999 - mae: 2.1856 - val_loss: 5.5183 - val_mae: 1.9125\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.6830 - mae: 2.1852 - val_loss: 6.0493 - val_mae: 2.0786\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.9246 - mae: 2.2494 - val_loss: 5.7734 - val_mae: 1.8955\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.6664 - mae: 2.2049 - val_loss: 6.1616 - val_mae: 2.0830\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3680 - mae: 2.1699 - val_loss: 5.7302 - val_mae: 1.9937\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.2829 - mae: 2.1667 - val_loss: 5.8426 - val_mae: 2.0364\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3009 - mae: 2.1821 - val_loss: 6.6295 - val_mae: 2.1687\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.2140 - mae: 2.1702 - val_loss: 5.3535 - val_mae: 1.8574\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3446 - mae: 2.1753 - val_loss: 6.6873 - val_mae: 2.1843\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3336 - mae: 2.1927 - val_loss: 5.5229 - val_mae: 1.9125\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.5070 - mae: 2.1817 - val_loss: 7.3431 - val_mae: 2.3611\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3631 - mae: 2.2055 - val_loss: 5.1246 - val_mae: 1.7256\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.2660 - mae: 2.1670 - val_loss: 6.1004 - val_mae: 2.0780\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0819 - mae: 2.1521 - val_loss: 5.9962 - val_mae: 2.0809\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.0370 - mae: 2.1425 - val_loss: 5.7209 - val_mae: 1.9590\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.0166 - mae: 2.1417 - val_loss: 5.7825 - val_mae: 1.9482\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3683 - mae: 2.2117 - val_loss: 5.5545 - val_mae: 1.8307\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.2184 - mae: 2.1519 - val_loss: 6.0607 - val_mae: 2.0578\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0014 - mae: 2.1389 - val_loss: 5.9802 - val_mae: 2.0630\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0566 - mae: 2.1548 - val_loss: 5.3025 - val_mae: 1.8120\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.4230 - mae: 2.1460 - val_loss: 8.0709 - val_mae: 2.4566\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.4109 - mae: 2.1635 - val_loss: 5.3102 - val_mae: 1.8314\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3384 - mae: 2.1868 - val_loss: 5.0740 - val_mae: 1.6902\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.3195 - mae: 2.1621 - val_loss: 6.2452 - val_mae: 2.1122\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.7750 - mae: 2.1202 - val_loss: 5.6260 - val_mae: 1.9304\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.6495 - mae: 2.1192 - val_loss: 5.7260 - val_mae: 1.9253\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.7174 - mae: 2.1186 - val_loss: 5.4702 - val_mae: 1.8560\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.6263 - mae: 2.1168 - val_loss: 5.5942 - val_mae: 1.9280\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.8120 - mae: 2.1255 - val_loss: 5.7002 - val_mae: 1.9387\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.7500 - mae: 2.0935 - val_loss: 6.1951 - val_mae: 2.0908\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.7803 - mae: 2.1608 - val_loss: 5.1992 - val_mae: 1.7445\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.7726 - mae: 2.1413 - val_loss: 5.7030 - val_mae: 1.9674\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.6532 - mae: 2.1216 - val_loss: 5.2480 - val_mae: 1.7733\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.7086 - mae: 2.1200 - val_loss: 6.5420 - val_mae: 2.1466\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.6889 - mae: 2.1230 - val_loss: 5.5834 - val_mae: 1.9068\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.5774 - mae: 2.1083 - val_loss: 5.2220 - val_mae: 1.7909\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.6902 - mae: 2.1451 - val_loss: 5.4217 - val_mae: 1.7921\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.7196 - mae: 2.1445 - val_loss: 6.7594 - val_mae: 2.1359\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.5559 - mae: 2.0882 - val_loss: 5.1099 - val_mae: 1.7573\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.4300 - mae: 2.1088 - val_loss: 5.6175 - val_mae: 1.8937\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.3638 - mae: 2.0802 - val_loss: 5.7147 - val_mae: 1.9520\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 8.3612 - mae: 2.0816 - val_loss: 5.6272 - val_mae: 1.8885\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.4293 - mae: 2.0963 - val_loss: 6.1244 - val_mae: 2.0567\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.3780 - mae: 2.0911 - val_loss: 5.3121 - val_mae: 1.7904\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.9372 - mae: 2.1717 - val_loss: 6.2325 - val_mae: 2.0321\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.3748 - mae: 2.0935 - val_loss: 5.4233 - val_mae: 1.8363\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.2159 - mae: 2.0775 - val_loss: 5.6518 - val_mae: 1.8894\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.1927 - mae: 2.0547 - val_loss: 6.2985 - val_mae: 2.0508\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.6043 - mae: 2.1128 - val_loss: 5.5401 - val_mae: 1.8703\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.1778 - mae: 2.0867 - val_loss: 5.3291 - val_mae: 1.7929\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.2174 - mae: 2.0626 - val_loss: 5.9672 - val_mae: 2.0047\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.1822 - mae: 2.0893 - val_loss: 5.4552 - val_mae: 1.8774\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.1889 - mae: 2.0490 - val_loss: 5.4391 - val_mae: 1.8265\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0841 - mae: 2.0628 - val_loss: 5.4757 - val_mae: 1.8429\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0435 - mae: 2.0506 - val_loss: 5.6798 - val_mae: 1.9263\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.9992 - mae: 2.0564 - val_loss: 5.4103 - val_mae: 1.8141\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0318 - mae: 2.0629 - val_loss: 5.4505 - val_mae: 1.8208\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.9562 - mae: 2.0243 - val_loss: 5.4597 - val_mae: 1.8519\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0411 - mae: 2.0554 - val_loss: 5.8348 - val_mae: 1.9360\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.0083 - mae: 2.0557 - val_loss: 5.6174 - val_mae: 1.8678\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.1472 - mae: 2.0736 - val_loss: 5.3942 - val_mae: 1.7955\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8398 - mae: 2.0223 - val_loss: 5.9207 - val_mae: 1.9871\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0092 - mae: 2.0391 - val_loss: 5.5334 - val_mae: 1.8679\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8247 - mae: 2.0458 - val_loss: 5.0646 - val_mae: 1.7304\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.9693 - mae: 2.0357 - val_loss: 6.3317 - val_mae: 2.0445\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.9259 - mae: 2.0790 - val_loss: 5.1006 - val_mae: 1.7221\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.8916 - mae: 2.0521 - val_loss: 5.8071 - val_mae: 1.9605\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7546 - mae: 2.0121 - val_loss: 5.3741 - val_mae: 1.8320\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7257 - mae: 2.0264 - val_loss: 5.2004 - val_mae: 1.7413\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7713 - mae: 2.0186 - val_loss: 5.1004 - val_mae: 1.7511\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.6128 - mae: 2.0081 - val_loss: 5.6979 - val_mae: 1.9184\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.9414 - mae: 2.0732 - val_loss: 5.2349 - val_mae: 1.7952\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7253 - mae: 2.0501 - val_loss: 5.0484 - val_mae: 1.6719\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.8472 - mae: 2.0441 - val_loss: 6.0630 - val_mae: 2.0141\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7498 - mae: 2.0223 - val_loss: 5.2368 - val_mae: 1.8108\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.6508 - mae: 2.0237 - val_loss: 5.2014 - val_mae: 1.7341\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8959 - mae: 2.0344 - val_loss: 5.7117 - val_mae: 1.9738\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.7721 - mae: 2.0146 - val_loss: 4.9547 - val_mae: 1.7011\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.5176 - mae: 1.9957 - val_loss: 5.4746 - val_mae: 1.8808\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.5421 - mae: 2.0020 - val_loss: 4.9856 - val_mae: 1.6761\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7706 - mae: 2.0364 - val_loss: 5.3218 - val_mae: 1.8158\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7664 - mae: 2.0234 - val_loss: 5.7223 - val_mae: 1.9454\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7524 - mae: 2.0292 - val_loss: 5.4138 - val_mae: 1.8447\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8731 - mae: 2.0863 - val_loss: 5.1648 - val_mae: 1.6725\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.1075 - mae: 2.0869 - val_loss: 5.4008 - val_mae: 1.8409\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7694 - mae: 2.0175 - val_loss: 5.7135 - val_mae: 1.9058\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4550 - mae: 1.9777 - val_loss: 5.3243 - val_mae: 1.8310\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.5444 - mae: 2.0209 - val_loss: 5.1828 - val_mae: 1.6765\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8366 - mae: 2.0468 - val_loss: 5.4065 - val_mae: 1.8066\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.5837 - mae: 1.9969 - val_loss: 5.9540 - val_mae: 1.9629\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4197 - mae: 1.9999 - val_loss: 5.0909 - val_mae: 1.7143\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.4016 - mae: 1.9672 - val_loss: 5.6523 - val_mae: 1.8791\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4821 - mae: 1.9911 - val_loss: 5.1798 - val_mae: 1.7637\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.3972 - mae: 1.9806 - val_loss: 5.2044 - val_mae: 1.7935\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.6777 - mae: 2.0197 - val_loss: 5.1354 - val_mae: 1.6946\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3192 - mae: 1.9891 - val_loss: 5.0942 - val_mae: 1.7006\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3101 - mae: 1.9574 - val_loss: 5.1810 - val_mae: 1.7732\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3972 - mae: 1.9670 - val_loss: 5.6261 - val_mae: 1.9093\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.1839 - mae: 1.9386 - val_loss: 5.0511 - val_mae: 1.7094\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8529 - mae: 2.0132 - val_loss: 4.9612 - val_mae: 1.6467\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.4130 - mae: 1.9962 - val_loss: 5.4513 - val_mae: 1.8078\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8596 - mae: 2.0528 - val_loss: 7.7304 - val_mae: 2.2942\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.5594 - mae: 2.0250 - val_loss: 5.0681 - val_mae: 1.6387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.3318 - mae: 1.9402 - val_loss: 5.1702 - val_mae: 1.7197\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.1251 - mae: 1.9245 - val_loss: 5.1847 - val_mae: 1.7419\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.0774 - mae: 1.9351 - val_loss: 5.2575 - val_mae: 1.7673\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.1234 - mae: 1.9469 - val_loss: 5.4053 - val_mae: 1.8119\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.1063 - mae: 1.9454 - val_loss: 5.0937 - val_mae: 1.7238\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.3791 - mae: 1.9475 - val_loss: 4.8292 - val_mae: 1.6155\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.0553 - mae: 1.9256 - val_loss: 5.3763 - val_mae: 1.8386\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.0871 - mae: 1.9511 - val_loss: 4.9858 - val_mae: 1.6517\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.9662 - mae: 1.9209 - val_loss: 5.5114 - val_mae: 1.8186\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.3685 - mae: 2.0082 - val_loss: 5.1959 - val_mae: 1.6644\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.6858 - mae: 2.0259 - val_loss: 5.0042 - val_mae: 1.6921\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.1586 - mae: 1.9187 - val_loss: 5.4723 - val_mae: 1.7777\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.0977 - mae: 1.9156 - val_loss: 5.3132 - val_mae: 1.7509\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9681 - mae: 1.9231 - val_loss: 5.1082 - val_mae: 1.7088\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0013 - mae: 1.9147 - val_loss: 5.0427 - val_mae: 1.6943\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8685 - mae: 1.8949 - val_loss: 5.4391 - val_mae: 1.8238\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.8935 - mae: 1.9201 - val_loss: 5.0959 - val_mae: 1.6427\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.9922 - mae: 1.9188 - val_loss: 5.4232 - val_mae: 1.7821\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.9507 - mae: 1.9194 - val_loss: 5.5732 - val_mae: 1.7782\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8850 - mae: 1.9103 - val_loss: 5.3775 - val_mae: 1.7539\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.0266 - mae: 1.9142 - val_loss: 6.4580 - val_mae: 1.9865\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.0781 - mae: 1.9512 - val_loss: 5.2732 - val_mae: 1.6715\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.0788 - mae: 1.9109 - val_loss: 5.3997 - val_mae: 1.7197\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.2116 - mae: 1.9670 - val_loss: 5.8357 - val_mae: 1.9197\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8121 - mae: 1.9050 - val_loss: 4.9092 - val_mae: 1.5999\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8585 - mae: 1.8949 - val_loss: 6.1835 - val_mae: 1.9920\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.0553 - mae: 1.9605 - val_loss: 5.1640 - val_mae: 1.5818\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.9174 - mae: 1.9327 - val_loss: 5.4670 - val_mae: 1.7692\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.9858 - mae: 1.9057 - val_loss: 5.4133 - val_mae: 1.7611\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7252 - mae: 1.8846 - val_loss: 5.6083 - val_mae: 1.8274\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7880 - mae: 1.8954 - val_loss: 5.4120 - val_mae: 1.6863\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.6903 - mae: 1.8802 - val_loss: 5.2737 - val_mae: 1.7327\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.7061 - mae: 1.8741 - val_loss: 6.0882 - val_mae: 1.9442\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.1609 - mae: 1.9744 - val_loss: 5.2412 - val_mae: 1.6291\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.1347 - mae: 1.9512 - val_loss: 5.3550 - val_mae: 1.7468\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.7869 - mae: 1.8945 - val_loss: 6.0133 - val_mae: 1.8871\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7561 - mae: 1.9104 - val_loss: 5.1114 - val_mae: 1.6857\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.6110 - mae: 1.8685 - val_loss: 5.1837 - val_mae: 1.6988\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8114 - mae: 1.8885 - val_loss: 7.0066 - val_mae: 2.0886\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.7663 - mae: 1.8638 - val_loss: 5.1359 - val_mae: 1.6644\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5706 - mae: 1.8643 - val_loss: 5.4494 - val_mae: 1.7332\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.7162 - mae: 1.8797 - val_loss: 5.6325 - val_mae: 1.7973\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5759 - mae: 1.8694 - val_loss: 5.8823 - val_mae: 1.8540\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.9596 - mae: 1.9500 - val_loss: 5.4853 - val_mae: 1.6871\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.5296 - mae: 1.8595 - val_loss: 5.6625 - val_mae: 1.8018\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.5181 - mae: 1.8453 - val_loss: 5.5006 - val_mae: 1.7636\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5281 - mae: 1.8541 - val_loss: 5.2131 - val_mae: 1.6727\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.4793 - mae: 1.8434 - val_loss: 6.0201 - val_mae: 1.8905\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5473 - mae: 1.8538 - val_loss: 5.3229 - val_mae: 1.6296\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5228 - mae: 1.8677 - val_loss: 5.6029 - val_mae: 1.7492\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5523 - mae: 1.8573 - val_loss: 5.2150 - val_mae: 1.6323\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.4868 - mae: 1.8521 - val_loss: 5.1695 - val_mae: 1.6767\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.5325 - mae: 1.8487 - val_loss: 5.8309 - val_mae: 1.8208\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5275 - mae: 1.8563 - val_loss: 5.5694 - val_mae: 1.7576\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.4637 - mae: 1.8401 - val_loss: 5.5996 - val_mae: 1.7686\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, validation_split=0.05, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16b8f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 9.7706 - mae: 2.4619\n",
      "MSE on test data = 9.770576477050781\n",
      "MAE on test data = 2.4618842601776123\n"
     ]
    }
   ],
   "source": [
    "mse, mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"MSE on test data = {mse}\")\n",
    "print(f\"MAE on test data = {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed1e14ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "First Prediction: 24.275279998779297\n",
      "First Actual value: 22.3\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"First Prediction: {y_pred[0][0]}\")   # First Prediction\n",
    "print(f\"First Actual value: {y_test[169]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e54028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
